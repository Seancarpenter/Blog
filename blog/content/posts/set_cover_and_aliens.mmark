+++
title = "Set Cover and Aliens"
author = "Sean Carpenter"
date = "2020-01-01"
description = "A close look at the classic set cover search problem through a post-apocalyptic lens"
featured_image = "posts/2020/set_cover_and_aliens/alien_abduction.png"
libraries = ["katex"]
+++


## The Scenario
![Warning Aliens](/images/posts/2020/set_cover_and_aliens/sign.png)

The year is 3000. Aliens have invaded and enslaved nearly the entire human race. You however have somehow managed to stay safe and out of sight from your would-be alien overlords, and are safely hidden in a small house in a rural part of the country. However, supplies are beginning to wear thin, and before long you know you're going to need to retrieve these 4 different items from the abandoned buildings around you if you want to survive.

![All Items](/images/posts/2020/set_cover_and_aliens/all_items.png)

You've been hiding out here for a long time, and as such are rather familiar with the area. You know exactly where to find these items, but traveling to the different buildings for supplies is going to be risky. While you are out in the open, you're at risk of being abducted by a roving UFO's tractor beam, vaporized, or worse! Analyzing a map of the area indicates that there are 4 buildings within equal distance of each other that combined have all of the resources you need.

![The Scenario](/images/posts/2020/set_cover_and_aliens/scenario.png)

Additionally, your current circumstances indicate that you only need one of each item. Retrieving more than one copy of each item is simply not going to increase your chances of survival. With that in mind, which of these buildings should you visit to get **ALL** the items you need in the **MINIMUM** amount of trips? At a glance, it should be easy to tell that we should visit **Location 1** and **Location 4** to get the supplies we need, and that the minimum number of trips that we'll need to make to get all of our supplies is **2**. However, what if we wanted to devise an algorithm to find 100 items from 20 different locations? Well we'd need to come up with an algorithm of course! As we'll soon find out, hidden within this relatively silly scenario is a deceptively hard problem known as the [Set Cover Search Problem](https://en.wikipedia.org/wiki/Set_cover_problem). Before we try and come up with an algorithm however, let's take a step back and see if we can turn this problem into something a bit more generic.


## Abstracting The Problem

To start off with, we can think of our items and locations as a set of subsets $$S = \{S_0, S_1, S_2\ ...\}$$, and the union of all subsets in $$S$$ as the universal set $$U$$. In mathematical notation:

$$
U = \bigcup\limits^n _{i=0} S_i
$$

<p style="text-align:center"> where $$n$$ is the number of subsets in $$S$$.

$$e.g.$$

<p style="text-align:center">The universal set $$U$$ of $$\{\{1, 2\},\ \{4, 5\},\ \{2, 3\}\} = \{1, 2, 3, 4, 5\}$$

Next, we're going to use the variable $$P$$ to denote the [power set](https://en.wikipedia.org/wiki/Power_set) of $$S$$, or $$p(S)$$. The power set is defined as the set of all subsets of a given set, including the empty set $$\emptyset$$ and $$S$$ itself.

$$e.g.$$

$$
p(\{1, 2\}) = \{\{\emptyset\},\ \{1\},\ \{2\},\ \{1, 2\}\}
$$

Lastly, let's use $$O$$ to denote the **optimal** (or minimal) set cover solution to any given set of subsets $$S$$. This in constrast to a **suboptimal** set cover solution, which is a set cover solution that is **NOT** minimal.

$$e.g.$$

<p style="text-align:center">The optimal set cover solution $$O$$ of $$S$$ where $$S = \{\{1, 2\}, \{3, 4\}, \{2, 3\}\}$$ is $$\{\{1, 2\}, \{3, 4\}\}$$

## Devising An Algorithm

With these tools at our disposal, lets see if we can come up with an algorithm. To start, one can readily deduce that if the power set $$p(S)$$, or $$P$$, contains all possible combinations of subsets in $$S$$, and our optimal solution $$O \subset S$$, then $$O \in P$$. Therefore, every possible set cover solution in $$S$$ (be it optimal or suboptimal) can be found within $$P$$ as well. As a result, finding $$O$$ is as simple as iterating through all of the sets in $$P$$ to find the set $$S$$ with the least amount of subsets where $$\bigcup\limits^n _i S_i = U$$

Ultimately, our solution is going to look something like:

    def optimal_set_cover(S)
        P = power_set(S)
        U = universe(S)
        O = S
        for each set PSi in P
            PSi_U = universe(PSi)
            if PSi_U == U and len(PSi) < len(O)
                O = PSi
        return O

Alright! With some psuedocode to guide our path, let's try and implement a working solution in Python.

## Implementation

For starters we're going to need to write a function to generate power sets. As generating power sets isn't the focus of this post, we're simply going to use a recipe directly from the [python itertools recipe book](https://docs.python.org/3/library/itertools.html#itertools-recipes) to do it for us.

{{< highlight python >}}
from itertools import chain, combinations

def power_set(iterable):
    s = list(iterable)
    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))
{{< /highlight >}}

```
>>> [s for s in power_set([1, 2, 3])]
[(), (1,), (2,), (3,), (1, 2), (1, 3), (2, 3), (1, 2, 3)]
```
Note, as you can see from the sample output, this is going to generate a list of tuples instead of sets like we might expect. We could easily modify this function to convert these tuples into sets, but doing so would significantly increase our final run time complexity. Given that our code will be able handle these tuples the same as if they were sets (as they're both [iterables](https://docs.python.org/3/glossary.html)), this is an unnecessary step that I have intentionally left out.

We're also going to need a function to generate the universe of a set of subsets. This will work pretty much exactly as described in the previous section of this post; simply iterate through a set of subsets (or sos) and union each one together to form the universe of that set of subsets.

{{< highlight python >}}
def universe(sos):
    u = set()
    for s in sos:
        u = u.union(s)
    return u
{{< /highlight >}}
```
>>> universe([{1, 2, 3}, {4, 5}, {6}])
{1, 2, 3, 4, 5, 6}
```

With these two functions at our disposal, we now have everything we need to implement our optimal set cover solution algorithm:

{{< highlight python >}}
def optimal_set_cover(sos):
    u = universe(sos)
    power_sos = power_set(sos)
    min_sos = sos # The minimal set cover solution found so far.
    for s in power_sos:
        if universe(s) == u and len(s) < len(min_sos):
            min_sos = s
    return list(min_sos)
{{< /highlight >}}
```
>>> optimal_set_cover([{1, 2}, {2, 3}, {3, 4}])
[{1, 2}, {3, 4}]
```

Alright problem solved! Time to go home!

...Right?

## Analyzing Our Implementation

Unfortunately, as you may have guessed when I mentioned deriving our answer from the power set of $$S$$, this algorithm is very, **VERY** slow. So slow that any attempt to generate a solution for more than 50 subsets is going to be realistically **impossible** to calculate for any computer. But wait, it gets worse; this is about as fast as generating optimal set cover solutions gets. Unfortunately, no algorithm exists that can generate an optimal set cover solution without having to calculate $$p(S)$$ in the worst case. As generating $$p(S)$$ has a worst case run time complexity of $$O(2^n)$$, no optimal set cover algorithm will ever achieve a better worst case run time complexity. Because of this, the set cover problem is said to fall under the class of [NP-Complete](https://en.wikipedia.org/wiki/NP-completeness) problems, a set of problems that are all extremely difficult to compute.

To put into perspective how incredibly slow an algorithm with a worst case run time complexity greater than or equal to $$O(2^n)$$ is, lets create some benchmarks for our code. To properly benchmark our code however, we're going to need to first write a function to generate sufficiently complicated sets of subsets. This small helper function should do the trick.

{{< highlight python >}}
import random

def generate_random_sos(num_elements, num_sets):
    return [set([random.choice([z for z in range(1, num_elements + 1)])
        for y in range(1, random.randint(1, num_elements))])
        for x in range(num_sets)]
{{< /highlight >}}

```
>>> generate_random_sos(5, 3)
[{4, 5}, {3, 4}, {1, 5}]
```

Using the [timeit](https://docs.python.org/3/library/timeit.html) library along side our code yielded the following results.

```
optimal_set_cover(generate_random_sos(10, 10)) # 0.0028 seconds
optimal_set_cover(generate_random_sos(15, 15)) # 0.113 seconds
optimal_set_cover(generate_random_sos(20, 20)) # 5.08 seconds
optimal_set_cover(generate_random_sos(25, 25)) # 251.313 seconds
optimal_set_cover(generate_random_sos(30, 30)) # 6092.618 seconds

All benchmarks were recorded on a 2014 Macbook Pro.
```

Extrapolating upon this trend, we can estimate that calculating the optimal set cover for a set of subsets with 50 subsets and 50 unique values would take over 200 years to compute!

So that's it right? No solution exists that can realistically compute this problem for anything larger than a handful of sets and we're all doomed.

...Right?

Well, not all hope is lost if we're alright with moving the goal posts a little. Instead of trying to find the absolute optimal set cover solution for any given set of subsets, what if we were okay with a solution that was **close-enough**? In other words, a suboptimal solution. If so, we're back in business because there just so happens to be an algorithm that can generate a pretty good suboptimal set cover solution (how good is beyond the scope of this post, but you can read more [here](https://en.wikipedia.org/wiki/Set_cover_problem#Greedy_algorithm) if you'd like) that runs in $$O(n^2log(n))$$ time!

## Taking A Greedy Approach

Key to most approximation algorithms is a solid heuristic, and this problem is no exception! One simple heuristic we could use is simply the size of each subset. After all, the larger the subset, the larger the amount of potentially uncovered elements that might exist in that subset. Using this heuristic, lets try implementing a greedy algorithm that builds a set cover solution using only the largest sets.

{{< highlight python >}}
def suboptimal_set_cover_1(sos):
    u = universe(sos)
    sos = sorted(sos, key=len)
    min_sos = [] # The minimal set cover solution found so far.
    ku = set() # The universe of elements covered so far, the "known universe".
    while ku != u:
        s = sos.pop()
        # Sanity check: Don't add a set if it doesn't increase our coverage.
        if len(ku.union(s)) > len(ku):
            min_sos.append(s)
            ku = ku.union(s)
    return min_sos
{{< /highlight >}}
```
>>> suboptimal_set_cover_1([{1, 2, 3}, {4, 5}, {3}])
[{1, 2, 3}, {4, 5}] # Perfect!

suboptimal_set_cover_1([{1, 2}, {3, 4}, {2, 3}, {2}])
[{2, 3}, {3, 4}, {1, 2}] # Okay...

>>> suboptimal_set_cover_1([{1, 2, 3}, {2, 3, 4}, {4, 5, 6}])
[{4, 5, 6}, {2, 3, 4}, {1, 2, 3}] # Yikes!
```

So, our solution isn't perfect, but it's not the worst! Additionally, it's lightning fast compared to our optimal set cover algorithm, operating with a worst case run time complexity of $$O(nlog(n))$$ (the time complexity it takes to sort our set of subsets). Notably, our algorithm really suffers when faced with sets of subsets where most of the subsets are of a similar same size. In the special case where all subsets are the same size, our algorithm completely falls flat, as all subsets are weighted equally according to our heuristic.

## Fine Tuning Our Heuristic

{{< highlight python >}}
def suboptimal_set_cover_2(sos):
    u = universe(sos)
    min_sos = [] # The minimal set cover solution found so far.
    ku = set() # The universe of elements covered so far, the "known universe".
    while ku != u:
        sos = sorted(sos, key=lambda s: len(s.difference(ku)))
        s = sos.pop()
        min_sos.append(s)
        ku = ku.union(s)
    return min_sos
{{< /highlight >}}
